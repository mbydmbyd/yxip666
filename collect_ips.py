import requests
import re
import os
import time
from collections import defaultdict

# ============================================
# åŸºç¡€é…ç½®
# ============================================
urls = [
    'https://api.uouin.com/cloudflare.html',
    'https://ip.164746.xyz',
    'https://ipdb.api.030101.xyz/?type=bestcf&country=true',
    'https://cf.090227.xyz',
    'https://addressesapi.090227.xyz/CloudFlareYes',
    'https://addressesapi.090227.xyz/ip.164746.xyz',
    'https://ipdb.api.030101.xyz/?type=bestcf&country=true',
    'https://raw.githubusercontent.com/ymyuuu/IPDB/refs/heads/main/bestcf.txt'
]

zip_data_url = "https://zip.cm.edu.kg/all.txt"  # ğŸ‡¯ğŸ‡µğŸ‡¸ğŸ‡¬ğŸ‡°ğŸ‡·ğŸ‡­ğŸ‡° æ•°æ®æº
zip_target_regions = ["JP", "SG", "KR", "HK"]
zip_count_per_region = 30  # æ¯ä¸ªåœ°åŒºå– 30 æ¡

ip_pattern = r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}'

# ============================================
# GitHub å¤šæºè®¾ç½®ï¼ˆå¯è‡ªå®šä¹‰ï¼‰
# ============================================
github_sources = [
    "https://raw.githubusercontent.com/JiangXi9527/CNJX/refs/heads/main/test-ip.txt",
    # "https://raw.githubusercontent.com/ymyuuu/IPDB/refs/heads/main/bestcf.txt",
    # å¯ä»¥å†æ·»åŠ æ›´å¤šæº
]

# æ¯ä¸ªåœ°åŒºè¦å–å¤šå°‘æ¡ï¼ˆä»… GitHub æºä½¿ç”¨ï¼‰
github_targets = {
    "SG": 30,  # æ–°åŠ å¡
    "JP": 20,  # æ—¥æœ¬
    "KR": 20,  # éŸ©å›½
    "HK": 20,  # é¦™æ¸¯
}

# ============================================
# ä» zip.cm.edu.kg/all.txt è·å–åœ°åŒºæ•°æ®
# ============================================
def fetch_zip_region_ips(url, regions, n_each=30):
    print(f"æ­£åœ¨ä» {url} è·å–æŒ‡å®šåœ°åŒºæ•°æ®...")
    resp = requests.get(url, timeout=10)
    resp.raise_for_status()
    lines = resp.text.splitlines()

    region_keys = {
        "JP": ["JP", "Japan", "æ—¥æœ¬"],
        "SG": ["SG", "Singapore", "æ–°åŠ å¡"],
        "KR": ["KR", "Korea", "éŸ©å›½"],
        "HK": ["HK", "Hong Kong", "é¦™æ¸¯"]
    }

    results = {r: [] for r in regions}
    cidr_pattern = r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}(?:/\d{1,2})?'

    def belongs_region(line, keys):
        line_lower = line.lower()
        return any(k.lower() in line_lower for k in keys)

    for line in lines:
        stripped = line.strip()
        if not stripped:
            continue
        for region, keys in region_keys.items():
            if region in regions and belongs_region(stripped, keys):
                m = re.search(cidr_pattern, stripped)
                if m and len(results[region]) < n_each:
                    results[region].append(m.group(0))
                break
        if all(len(results[r]) >= n_each for r in regions):
            break

    print("âœ… è·å–å®Œæ¯•ï¼š")
    for r in regions:
        print(f"  {r}: {len(results[r])} æ¡")
    return results


# ============================================
# ä»å¤šä¸ª GitHub æºä¸­æå–å„åœ°åŒº IPï¼ˆä¸æŸ¥ ISPï¼‰
# ============================================
def fetch_github_region_ips(sources, targets):
    print(f"æ­£åœ¨ä» GitHub æºè·å–å¤šåœ°åŒº IP...")
    results = {r: [] for r in targets.keys()}
    region_keys = {
        "JP": ["JP", "Japan", "æ—¥æœ¬"],
        "SG": ["SG", "Singapore", "æ–°åŠ å¡"],
        "KR": ["KR", "Korea", "éŸ©å›½"],
        "HK": ["HK", "Hong Kong", "é¦™æ¸¯"]
    }

    for src in sources:
        print(f"ğŸ”¹ æ£€ç´¢æº: {src}")
        try:
            resp = requests.get(src, timeout=10)
            resp.raise_for_status()
            lines = resp.text.splitlines()
            for line in lines:
                stripped = line.strip()
                if not stripped:
                    continue
                for region, keys in region_keys.items():
                    if region not in targets:
                        continue
                    if any(k.lower() in stripped.lower() for k in keys):
                        m = re.search(ip_pattern, stripped)
                        if m and len(results[region]) < targets[region]:
                            results[region].append(m.group(0))
                            break
            time.sleep(0.3)
        except Exception as e:
            print(f"âŒ è¯·æ±‚ {src} å¤±è´¥: {e}")

    for r, ips in results.items():
        print(f"âœ… {r}: å…±è·å– {len(ips)} ä¸ª IP")
    return results


# ============================================
# ç¼“å­˜ç³»ç»Ÿ
# ============================================
cache = {}
if os.path.exists("ip.txt"):
    with open("ip.txt", "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if "#" in line:
                parts = line.split("#")
                if len(parts) == 3:
                    ip, location, isp = parts
                    if "-" in location:
                        location = location.split("-")[0]
                    cache[ip] = f"{location}#{isp}"
                elif len(parts) == 2:
                    ip, location = parts
                    if "-" in location:
                        location = location.split("-")[0]
                    cache[ip] = f"{location}#æœªçŸ¥ISP"

# ============================================
# æ™®é€šç½‘é¡µæºæŠ“å–
# ============================================
ip_set = set()
for url in urls:
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        html_text = response.text
        ip_matches = re.findall(ip_pattern, html_text)
        ip_set.update(ip_matches)
        print(f"âœ… ä» {url} æŠ“å–åˆ° {len(ip_matches)} ä¸ª IP")
    except Exception as e:
        print(f"âŒ è¯·æ±‚ {url} å¤±è´¥: {e}")

# ============================================
# æ·»åŠ  zip.cm.edu.kg çš„æ•°æ®
# ============================================
zip_region_ips = fetch_zip_region_ips(zip_data_url, zip_target_regions, zip_count_per_region)
for region, ips in zip_region_ips.items():
    for ip in ips:
        ip_set.add(ip)
        cache[ip] = f"{region}#zip.cm.edu.kg"

# ============================================
# æ·»åŠ  GitHub å¤šæºæ•°æ®
# ============================================
github_region_ips = fetch_github_region_ips(github_sources, github_targets)
for region, ips in github_region_ips.items():
    for ip in ips:
        ip_set.add(ip)
        cache[ip] = f"{region}#github"

# ============================================
# æŸ¥è¯¢ IP æ‰€å±å›½å®¶/åœ°åŒº/ISPï¼ˆå¯¹é zip/github æºï¼‰
# ============================================
def get_ip_info(ip):
    try:
        r = requests.get(f"http://ip-api.com/json/{ip}?lang=zh-CN", timeout=5)
        data = r.json()
        if data["status"] == "success":
            location = f"{data.get('country', '')} {data.get('regionName', '')}".strip()
            isp = data.get("isp", "æœªçŸ¥ISP")
            return f"{location}#{isp}"
        else:
            return "æœªçŸ¥åœ°åŒº#æœªçŸ¥ISP"
    except:
        return "æŸ¥è¯¢å¤±è´¥#æœªçŸ¥ISP"


results = {}
for ip in sorted(ip_set):
    if ip in cache:
        info = cache[ip]
    else:
        info = get_ip_info(ip)
        time.sleep(0.5)
    results[ip] = info

# ============================================
# æŒ‰åœ°åŒºåˆ†ç»„ + ç¼–å·è¾“å‡º
# ============================================
grouped = defaultdict(list)
for ip, info in results.items():
    region, isp = info.split("#")
    grouped[region].append((ip, isp))

with open("ip.txt", "w", encoding="utf-8") as f:
    for region in sorted(grouped.keys()):
        for idx, (ip, isp) in enumerate(sorted(grouped[region]), 1):
            f.write(f"{ip}#{region}-{idx}#{isp}\n")
        f.write("\n")

print(f"\nğŸ¯ å…±ä¿å­˜ {len(results)} ä¸ªå”¯ä¸€ IP åœ°å€ï¼ˆå« zip.cm.edu.kg å„åŒºä¸ GitHub å¤šæºæ•°æ®ï¼‰ã€‚")
